name: Need Scanner Daily

on:
  schedule:
    # Run every day at 06:15 UTC (08:15 Paris time)
    - cron: "15 6 * * *"
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      pack:
        description: 'Subreddit pack to use'
        required: false
        default: 'smallbiz_fr'
      reddit_limit:
        description: 'Posts per subreddit'
        required: false
        default: '240'

jobs:
  scan:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -e .

      - name: Create data directories
        run: |
          mkdir -p data/raw
          mkdir -p data/history
          mkdir -p data/daily

      - name: Collect posts
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python -m need_scanner collect-all \
            --pack ${{ github.event.inputs.pack || 'smallbiz_fr' }} \
            --reddit-limit ${{ github.event.inputs.reddit_limit || '240' }} \
            --reddit-mode hot \
            --hn-days 30 \
            --rss-days 30 \
            --include-keywords-file config/intent_patterns.txt \
            --history-days 45 \
            --filter-lang en,fr \
            --filter-intent

      - name: Prefilter posts
        run: |
          python -m need_scanner prefilter \
            --filter-lang en,fr \
            --filter-intent \
            --keep-intents pain,request \
            --detect-wtp

      - name: Run pipeline
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python -m need_scanner run \
            --clusters 12 \
            --novelty-weight 0.15 \
            --trend-weight 0.15 \
            --history-path data/history \
            --output-dir data/daily/$(date +%Y%m%d)

      - name: Verify output files exist
        run: |
          echo "Listing data/daily directory:"
          ls -laR data/daily/
          echo ""
          echo "Checking for CSV files:"
          find data/daily -name "*.csv" -type f || echo "No CSV files found"
          echo ""
          echo "Checking for JSON files:"
          find data/daily -name "*.json" -type f || echo "No JSON files found"

      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: daily-insights-${{ github.run_number }}
          path: |
            data/daily/**/insights_enriched.csv
            data/daily/**/cluster_results.json
          retention-days: 30
          if-no-files-found: error

      # Optional: Commit history files back to repo
      - name: Commit history
        if: success()
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add data/history/*.json || true
          git diff --quiet && git diff --staged --quiet || git commit -m "Update history [skip ci]"
          git push || true

      # Send Slack notification with Python (handles special characters properly)
      - name: Send Slack notification
        if: success()
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          export OUTPUT_DIR="data/daily/$(date +%Y%m%d)"

          python3 << 'EOF'
          import json
          import os
          import csv
          import urllib.request
          import traceback

          output_dir = os.environ.get('OUTPUT_DIR')
          webhook_url = os.environ['SLACK_WEBHOOK_URL']
          run_url = "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"

          print(f"Looking for files in: {output_dir}")

          # Extract metrics
          try:
              meta_path = f'{output_dir}/meta.json'
              with open(meta_path, 'r') as f:
                  meta = json.load(f)
                  total_posts = len(meta)
              print(f"Found {total_posts} posts")
          except Exception as e:
              print(f"Error reading meta.json: {e}")
              total_posts = "N/A"

          # Read cluster results for cost info
          try:
              results_path = f'{output_dir}/cluster_results.json'
              with open(results_path, 'r') as f:
                  results = json.load(f)
                  cost_info = results.get('cost_breakdown', {})
                  total_cost = cost_info.get('total', 'N/A')
          except:
              total_cost = "N/A"

          # Extract top clusters
          top_clusters = []
          clusters_count = "N/A"
          try:
              csv_path = f'{output_dir}/insights_enriched.csv'
              with open(csv_path, 'r', encoding='utf-8') as f:
                  reader = csv.DictReader(f)
                  rows = list(reader)
                  clusters_count = len(rows)

                  # Get top 5 (or all if less than 5)
                  for i, row in enumerate(rows[:5], 1):
                      top_clusters.append({
                          'rank': i,
                          'title': row['title'],
                          'score': float(row['priority_score']),
                          'pain': row.get('pain_score_final', 'N/A'),
                          'novelty': row.get('novelty_score', 'N/A'),
                          'trend': row.get('trend_score', 'N/A'),
                          'size': row.get('size', 'N/A')
                      })
                  print(f"Found {clusters_count} clusters")
          except Exception as e:
              print(f"Error reading insights: {e}")
              traceback.print_exc()

          # Build Slack blocks
          blocks = [
              {
                  "type": "header",
                  "text": {
                      "type": "plain_text",
                      "text": "ðŸŽ¯ Need Scanner Daily Results"
                  }
              },
              {
                  "type": "section",
                  "fields": [
                      {
                          "type": "mrkdwn",
                          "text": f"*ðŸ“Š Posts Analyzed*\n{total_posts}"
                      },
                      {
                          "type": "mrkdwn",
                          "text": f"*ðŸŽª Clusters Found*\n{clusters_count}"
                      },
                      {
                          "type": "mrkdwn",
                          "text": f"*ðŸ’° Total Cost*\n${total_cost}"
                      },
                      {
                          "type": "mrkdwn",
                          "text": f"*ðŸ“… Date*\n{os.path.basename(output_dir)}"
                      }
                  ]
              },
              {"type": "divider"}
          ]

          # Add top 5 priorities
          if top_clusters:
              blocks.append({
                  "type": "section",
                  "text": {
                      "type": "mrkdwn",
                      "text": "*ðŸ† Top 5 Priorities*"
                  }
              })

              for cluster in top_clusters:
                  emoji = "ðŸ¥‡" if cluster['rank'] == 1 else "ðŸ¥ˆ" if cluster['rank'] == 2 else "ðŸ¥‰" if cluster['rank'] == 3 else "â­"
                  blocks.append({
                      "type": "section",
                      "text": {
                          "type": "mrkdwn",
                          "text": f"{emoji} *#{cluster['rank']} - {cluster['title']}*\n"
                                  f"Priority: `{cluster['score']:.2f}` | "
                                  f"Pain: `{cluster['pain']}` | "
                                  f"Novelty: `{cluster['novelty']}` | "
                                  f"Trend: `{cluster['trend']}` | "
                                  f"Size: `{cluster['size']} posts`"
                      }
                  })

              blocks.append({"type": "divider"})

          # Add footer with instructions
          blocks.append({
              "type": "section",
              "text": {
                  "type": "mrkdwn",
                  "text": "ðŸ’¡ *How to download full results:*\n"
                          "Click the button below â†’ Scroll to *Artifacts* section â†’ Download `daily-insights-XXX.zip`"
              }
          })

          # Add action button
          blocks.append({
              "type": "actions",
              "elements": [
                  {
                      "type": "button",
                      "text": {
                          "type": "plain_text",
                          "text": "ðŸ“Š View Results & Download CSV"
                      },
                      "url": run_url,
                      "style": "primary"
                  }
              ]
          })

          # Build payload
          payload = {
              "text": "Need Scanner daily run complete!",
              "blocks": blocks
          }

          # Send to Slack
          req = urllib.request.Request(
              webhook_url,
              data=json.dumps(payload).encode('utf-8'),
              headers={'Content-Type': 'application/json'}
          )

          with urllib.request.urlopen(req) as response:
              print(f"Slack notification sent: {response.status}")
          EOF

      # - name: Cleanup old artifacts
      #   uses: geekyeggo/delete-artifact@v5
      #   if: success()
      #   with:
      #     name: daily-insights-*
      #     useGlob: true
      #     failOnError: false
