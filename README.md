# ğŸ” Need Scanner

**Radar de dÃ©couverte de marchÃ© multi-secteur** - DÃ©tecte automatiquement les besoins utilisateurs non satisfaits Ã  partir de posts Reddit, Hacker News, Stack Exchange et autres sources en ligne.

## ğŸ¯ Objectif

Transformer des milliers de posts utilisateurs en insights actionnables pour identifier des opportunitÃ©s de produits/services Ã  lancer.

## âœ¨ FonctionnalitÃ©s

### ğŸš€ **NOUVEAU : AmÃ©liorations Moteur (v2.0)**
- âœ… **Configuration Multi-ModÃ¨le** : gpt-4o pour TOP K, gpt-4o-mini pour le reste (optimisation coÃ»ts)
- âœ… **Tags Sectoriels** : Classification automatique en 13 secteurs (dev_tools, business_pme, health_wellbeing, etc.)
- âœ… **MMR Reranking** : SÃ©lection diversifiÃ©e des TOP N clusters (pertinence + diversitÃ©)
- âœ… **MÃ©moire Inter-Jour** : PÃ©nalitÃ© automatique des clusters similaires Ã  l'historique
- âœ… **Scoring Discriminant** : Prompts amÃ©liorÃ©s pour des scores pain/novelty/trend plus expressifs
- âœ… **Sources Multi-Secteur** : Configuration YAML avec catÃ©gories et quotas par secteur

### ğŸ¯ **NOUVEAU : AmÃ©liorations Ã‰TAPE 1 (2025-11)**
- âœ… **Trend Score LLM** : Score hybride marchÃ© (70% analyse LLM + 30% croissance historique)
- âœ… **Founder Fit Score** : Ã‰valuation adÃ©quation opportunitÃ© vs profil fondateur (1-10)
- âœ… **MVP amÃ©liorÃ©s** : Prompts optimisÃ©s pour Ã©viter les "guides PDF" et privilÃ©gier vrais produits/services

### ğŸ“š **NOUVEAU : Lib + Base SQLite (Ã‰TAPE 2)**
- âœ… **API Python** : Fonction `run_scan()` rÃ©utilisable pour intÃ©gration programmatique
- âœ… **Base SQLite** : Stockage persistant runs & insights (query, filtrage, historique)
- âœ… **CLI Enrichi** : Commandes `scan`, `list-runs`, `show-insights` pour usage simplifiÃ©
- âœ… **RÃ©trocompatibilitÃ©** : Conservation exports CSV/JSON + anciens scripts

ğŸ“– **Voir documentation** : [docs/ENGINE_IMPROVEMENTS.md](docs/ENGINE_IMPROVEMENTS.md) | [docs/STEP1_ENGINE_IMPROVEMENTS.md](docs/STEP1_ENGINE_IMPROVEMENTS.md) | [docs/STEP2_LIB_AND_DATABASE.md](docs/STEP2_LIB_AND_DATABASE.md)

### ğŸ“Š **Analyse Enrichie**
- **10 champs extraits par insight** : persona, Job-To-Be-Done, contexte, alternatives, signaux WTP, MVP suggÃ©rÃ©
- **Priority scoring** : Formule multi-composantes (Pain 30% + Traction 25% + Novelty 15% + WTP 20% + Trend 10%)
- **Founder Fit scoring** : Signal complÃ©mentaire pour filtrage personnel (1-10)
- **DÃ©tection WTP** : 7 types de signaux de volontÃ© de payer (FR/EN)
- **Classification intent** : 6 types (pain, request, howto, promo, news, other)
- **Support multilingue** : DÃ©tection de 23+ langues

### ğŸŒ **Sources Multi-Secteur**

**OpÃ©rationnelles (sans authentification)** :
- âœ… **Reddit** - 26+ subreddits (freelance, PME, santÃ©, Ã©ducation, restauration, marketing, etc.)
- âœ… **Hacker News** - Ask HN, Show HN
- âœ… **RSS feeds** - Flux personnalisables
- âœ… **Stack Exchange** - 14+ sites (stackoverflow, workplace, freelancing, startups, etc.)

**PrÃªtes (nÃ©cessitent API keys)** :
- ğŸ”‘ **Product Hunt** - Nouveaux produits et commentaires
- ğŸ”‘ **Twitter/X** - Recherches configurables

### ğŸ“ˆ **Pipeline Complet**

```
Collecte â†’ Filtrage â†’ DÃ©duplication â†’ Embeddings â†’ Clustering â†’ LLM Enrichi â†’ Priority Scoring â†’ Export
```

### ğŸ“¤ **Export**

- **JSON enrichi** : RÃ©sultats complets avec mÃ©tadonnÃ©es
- **CSV 20 colonnes** : Compatible Excel/Google Sheets
- Includes : rank, priority_score, persona, JTBD, context, alternatives, WTP signals, tous les scores

## ğŸš€ Installation

```bash
# Cloner le repo
git clone <repo-url>
cd need_scanner

# CrÃ©er environnement virtuel
python -m venv env
source env/bin/activate  # Linux/Mac
# env\Scripts\activate  # Windows

# Installer dÃ©pendances
pip install -r requirements.txt

# Configurer variables d'environnement
cp .env.example .env
# Ã‰diter .env et ajouter votre OPENAI_API_KEY
```

### Configuration Requise

**Obligatoire** :
- Python 3.11+
- OpenAI API Key (pour embeddings + LLM)

**Optionnel** :
- Product Hunt API Token
- Twitter API v2 credentials

## âš¡ Quick Start (NOUVEAU - CLI v2.1)

```bash
# 1. Collecter des posts
python -m need_scanner collect-reddit-multi --limit-per-sub 30

# 2. Lancer un scan complet (stockage DB + CSV)
python -m need_scanner scan --mode deep --max-insights 20

# 3. Voir les rÃ©sultats
python -m need_scanner show-insights <RUN_ID>

# 4. Lister l'historique
python -m need_scanner list-runs
```

**NouveautÃ© :** La commande `scan` orchestre tout le pipeline (embeddings, clustering, enrichissement LLM, scoring) et sauvegarde automatiquement dans une base SQLite + gÃ©nÃ¨re CSV/JSON.

## ğŸ“– Guide d'Utilisation DÃ©taillÃ©

### 1. Collecter des DonnÃ©es

**Reddit multi-subreddits** (recommandÃ©) :
```bash
python -m need_scanner collect-reddit-multi --limit-per-sub 30
# Collecte 30 posts de chaque subreddit configurÃ© (~780 posts)
```

**Hacker News** :
```bash
python -m need_scanner collect-hn --days 30 --min-points 20
```

**Stack Exchange** :
```bash
python -m need_scanner collect-stackexchange --sites stackoverflow,workplace --days 7
```

**Toutes les sources** :
```bash
python -m need_scanner collect-all --reddit-subreddit freelance --rss-feeds-file config/rss_feeds.txt
```

### 2. PrÃ©visualiser les DonnÃ©es

```bash
python -m need_scanner prefilter --filter-lang en --detect-wtp --show-sample 10
```

Affiche :
- Distribution des sources
- Distribution des langues
- Distribution des intents
- Signaux WTP dÃ©tectÃ©s
- Ã‰chantillon de posts

### 3. Analyser avec le Pipeline Complet

```bash
python -m need_scanner run --input "data/raw/posts_*.json" --clusters 5 --output-dir data/results
```

**Sortie** :
- `data/results/cluster_results.json` - RÃ©sultats complets
- `data/results/embeddings.npy` - Vecteurs d'embeddings
- `data/results/meta.json` - MÃ©tadonnÃ©es des posts

### 4. Exporter en CSV

Les rÃ©sultats JSON peuvent Ãªtre convertis en CSV enrichi (20 colonnes) avec les scripts fournis.

## ğŸ“Š Exemple de RÃ©sultat

```
#1 - Mauvaise prÃ©paration projet (Priority: 5.68/10)

ğŸ¯ Persona: Entrepreneur en technologie

ğŸ“‹ JTBD: Quand je commence un nouveau projet, je veux m'assurer que
         je rÃ©sous le bon problÃ¨me, afin de maximiser la valeur pour
         mes utilisateurs.

ğŸ˜£ ProblÃ¨me: Les utilisateurs se retrouvent souvent confrontÃ©s Ã  des
             problÃ¨mes inattendus dans leurs projets, ce qui entraÃ®ne
             une perte de temps et d'efforts.

ğŸ”§ Contexte: Outils de gestion de projet existants, mais manque de
             validation d'hypothÃ¨ses au dÃ©marrage.

ğŸ’¡ MVP: CrÃ©er un outil simple de validation d'idÃ©e qui permet aux
        utilisateurs de tester leurs hypothÃ¨ses rapidement.

ğŸ”„ Alternatives: [] (aucune!)

ğŸ’° WTP Signal: looking for paid solution

ğŸ“Š Scores:
   Pain (LLM):    9/10
   Traction:      5.0/10
   Novelty:       10.0/10
   Priority:      5.68/10
```

## ğŸ› ï¸ Configuration AvancÃ©e

### Reddit Multi-Subreddits

Ã‰diter `config/reddit_subs.txt` :
```
# Ajouter vos subreddits (un par ligne, sans r/)
freelance
Entrepreneur
smallbusiness
# ... etc
```

### Stack Exchange Sites

Ã‰diter `config/stackexchange_sites.txt` :
```
stackoverflow
workplace
freelancing
startups
```

### Product Hunt

1. Obtenir un token : https://www.producthunt.com/v2/oauth/applications
2. Ajouter Ã  `.env` : `PRODUCTHUNT_API_TOKEN=your_token`
3. Utiliser : `python -m need_scanner collect-producthunt --days 7`

## ğŸ’° CoÃ»ts

**Avec OpenAI API** :
- Embeddings (text-embedding-3-small) : ~$0.00001 par post
- Summarization (gpt-4o-mini) : ~$0.0002 par cluster

**Exemple rÃ©el** :
- 43 posts â†’ 5 clusters enrichis = **$0.0012**
- 200 posts â†’ 10 clusters = ~$0.02-0.05

## ğŸ“ Structure du Projet

```
need_scanner/
â”œâ”€â”€ src/need_scanner/
â”‚   â”œâ”€â”€ fetchers/          # Collecteurs de donnÃ©es
â”‚   â”‚   â”œâ”€â”€ reddit.py      # Reddit (multi-subreddit)
â”‚   â”‚   â”œâ”€â”€ hn.py          # Hacker News
â”‚   â”‚   â”œâ”€â”€ rss.py         # RSS feeds
â”‚   â”‚   â”œâ”€â”€ twitter.py     # Twitter/X
â”‚   â”‚   â”œâ”€â”€ producthunt.py # Product Hunt
â”‚   â”‚   â””â”€â”€ stackexchange.py # Stack Exchange
â”‚   â”œâ”€â”€ analysis/          # Analyse et enrichissement
â”‚   â”‚   â”œâ”€â”€ intent.py      # Classification intent
â”‚   â”‚   â”œâ”€â”€ wtp.py         # DÃ©tection WTP
â”‚   â”‚   â”œâ”€â”€ summarize.py   # LLM enrichi
â”‚   â”‚   â”œâ”€â”€ scoring.py     # Pain scoring
â”‚   â”‚   â””â”€â”€ priority.py    # Priority scoring
â”‚   â”œâ”€â”€ processing/        # Pipeline de traitement
â”‚   â”‚   â”œâ”€â”€ filters.py     # Filtres (langue, score, etc.)
â”‚   â”‚   â”œâ”€â”€ clean.py       # Nettoyage
â”‚   â”‚   â”œâ”€â”€ dedupe.py      # DÃ©duplication
â”‚   â”‚   â”œâ”€â”€ embed.py       # Embeddings
â”‚   â”‚   â””â”€â”€ cluster.py     # Clustering
â”‚   â”œâ”€â”€ export/            # Export des rÃ©sultats
â”‚   â”‚   â””â”€â”€ writer.py      # JSON + CSV
â”‚   â””â”€â”€ cli.py             # Interface CLI
â”œâ”€â”€ config/                # Fichiers de configuration
â”‚   â”œâ”€â”€ reddit_subs.txt    # Liste de subreddits
â”‚   â”œâ”€â”€ twitter_queries.txt # RequÃªtes Twitter
â”‚   â”œâ”€â”€ producthunt_categories.txt
â”‚   â”œâ”€â”€ stackexchange_sites.txt
â”‚   â””â”€â”€ rss_feeds.txt
â”œâ”€â”€ data/                  # DonnÃ©es (git-ignorÃ©)
â”‚   â”œâ”€â”€ raw/              # Posts collectÃ©s
â”‚   â””â”€â”€ results/          # RÃ©sultats d'analyse
â””â”€â”€ docs/                  # Documentation
    â”œâ”€â”€ SPRINT_TRACKING.md
    â”œâ”€â”€ DATA_GUIDE.md
    â””â”€â”€ IMPROVEMENT_PLAN.md
```

## ğŸ§ª Tests

**Test rapide (Sprint 1)** :
```bash
python test_sprint1.py
```
Analyse 43 posts filtrÃ©s â†’ 5 clusters enrichis ($0.0012)

**Prefilter sur dataset complet** :
```bash
python -m need_scanner prefilter --input-pattern "data/raw/posts_*.json" --filter-lang en --detect-wtp
```

## ğŸ“š Documentation ComplÃ¨te

- `docs/SPRINT_TRACKING.md` - Suivi des dÃ©veloppements
- `docs/DATA_GUIDE.md` - Guide des donnÃ©es
- `docs/IMPROVEMENT_PLAN.md` - Plan d'amÃ©lioration
- `.claude/` - Commandes Claude Code personnalisÃ©es

## ğŸ¤ Contributing

Ce projet a Ã©tÃ© dÃ©veloppÃ© avec Claude Code. Pour contribuer :

1. Fork le repo
2. CrÃ©er une branche feature
3. Commiter vos changements
4. Pousser vers la branche
5. Ouvrir une Pull Request

## ğŸ“ Licence

[SpÃ©cifier la licence]

## ğŸ™ Remerciements

- OpenAI pour les APIs (embeddings + GPT-4o-mini)
- Reddit, Hacker News, Stack Exchange pour les donnÃ©es publiques
- Claude Code pour l'assistance au dÃ©veloppement

## ğŸ“ˆ Roadmap

**ComplÃ©tÃ©** :
- âœ… Multi-source collection (7 sources)
- âœ… Analyse enrichie (10 champs)
- âœ… Priority scoring
- âœ… Export CSV 20 colonnes
- âœ… DÃ©tection WTP FR/EN

**v2.0 - AmÃ©liorations Moteur** (2025-01) :
- âœ… Configuration multi-modÃ¨le (light/heavy)
- âœ… Tags sectoriels automatiques
- âœ… MMR reranking pour diversitÃ©
- âœ… MÃ©moire inter-jour (historique)
- âœ… Scoring plus discriminant
- âœ… Sources multi-secteur Ã©quilibrÃ©es

**Ã€ venir** :
- [ ] Dashboard web interactif
- [ ] Notifications Slack/Discord enrichies
- [ ] Support App Store reviews
- [ ] IntÃ©gration Docker
- [ ] CI/CD pipeline

## ğŸ’¬ Support

Pour questions ou suggestions :
- Ouvrir une issue sur GitHub
- Consulter la documentation dans `docs/`

---

**Made with â¤ï¸ using Claude Code**
