# üöÄ Need Scanner Engine Improvements

Ce document d√©crit les am√©liorations majeures apport√©es au moteur Need Scanner pour rendre la d√©couverte de march√© plus **diversifi√©e**, **intelligente** et **pertinente**.

## üìã R√©sum√© des Am√©liorations

### ‚úÖ Impl√©ment√©

1. **Configuration Multi-Mod√®le OpenAI** (light/heavy)
2. **Tags Sectoriels par Cluster**
3. **Reranking MMR (Maximal Marginal Relevance)**
4. **M√©moire Inter-Jour des Clusters**
5. **Scoring Plus Discriminant**
6. **Configuration Multi-Secteur des Sources**

---

## 1. Configuration Multi-Mod√®le OpenAI

### üéØ Objectif
Optimiser les co√ªts en utilisant un mod√®le puissant uniquement pour les t√¢ches complexes, et un mod√®le l√©ger pour les t√¢ches simples.

### üìù Impl√©mentation

**Nouveaux param√®tres de configuration** (`.env`) :

```bash
# Mod√®le l√©ger : t√¢ches simples (classification secteur, intent)
NS_LIGHT_MODEL=gpt-4o-mini

# Mod√®le lourd : enrichissement complet (persona, JTBD, scoring)
NS_HEAVY_MODEL=gpt-4o

# TOP K enrichissement : nombre de clusters enrichis avec le mod√®le lourd
NS_TOP_K_ENRICHMENT=5
```

### üí∞ Impact Co√ªts

**Avant** : Tous les clusters enrichis avec `gpt-4o-mini` (~0.0002$/cluster)
**Apr√®s** :
- Top 5 clusters : `gpt-4o` (~0.002$/cluster) = **$0.010**
- Autres clusters : `gpt-4o-mini` (~0.0002$/cluster) = **$0.001**
- **Total** : ~$0.011 pour 10 clusters (vs $0.002 avant, mais avec bien plus de qualit√© sur le TOP 5)

### üìç Fichiers Modifi√©s
- `src/need_scanner/config.py` : Ajout des param√®tres light/heavy
- `.env.example` : Documentation des nouvelles variables
- `config.py` : Ajout du pricing gpt-4o

---

## 2. Tags Sectoriels par Cluster

### üéØ Objectif
Classifier automatiquement chaque cluster dans un secteur pour faciliter l'analyse multi-secteur et le reranking par diversit√©.

### üìù Impl√©mentation

**13 secteurs pr√©d√©finis** :
- `dev_tools` - Outils pour d√©veloppeurs
- `ai_llm` - IA et LLM
- `business_pme` - Business et PME
- `education_learning` - √âducation et formation
- `health_wellbeing` - Sant√© et bien-√™tre
- `consumer_lifestyle` - Lifestyle et consommation
- `creator_economy` - √âconomie des cr√©ateurs
- `workplace_hr` - Workplace et RH
- `finance_accounting` - Finance et comptabilit√©
- `legal_compliance` - L√©gal et conformit√©
- `marketing_sales` - Marketing et ventes
- `ecommerce_retail` - E-commerce et retail
- `other` - Autre

**Classification LLM** : Utilise le mod√®le l√©ger (`gpt-4o-mini`) pour classifier rapidement chaque cluster.

### üìä Nouveau Champ dans les Sch√©mas

```python
class EnrichedClusterSummary(BaseModel):
    ...
    sector: Optional[str] = None  # Nouveau champ
```

### üìç Fichiers Cr√©√©s
- `src/need_scanner/analysis/sector.py` : Module de classification
- `src/need_scanner/schemas.py` : Ajout du champ `sector`

---

## 3. Reranking MMR (Maximal Marginal Relevance)

### üéØ Objectif
S√©lectionner les TOP N clusters en **maximisant la diversit√©** tout en conservant la pertinence.

### üìù Principe MMR

**Formule** :
```
MMR(d) = Œª * Relevance(d) - (1 - Œª) * max[Similarity(d, d_i) for d_i in Selected]
```

- **Œª = 0.7** (par d√©faut) : 70% pertinence, 30% diversit√©
- Plus Œª est √©lev√©, plus on privil√©gie la pertinence
- Plus Œª est faible, plus on privil√©gie la diversit√©

### üé® Deux Modes de Reranking

#### Mode 1 : MMR Global
S√©lectionne les TOP K en maximisant la diversit√© globale.

```python
reranked_items, _ = mmr_rerank(
    items=insights,
    embeddings=cluster_embeddings,
    priority_scores=priority_scores,
    top_k=10,
    lambda_param=0.7
)
```

#### Mode 2 : MMR par Secteur
Garantit une repr√©sentation √©quilibr√©e de chaque secteur.

```python
reranked_items, _ = mmr_rerank_by_sector(
    items=insights,
    embeddings=cluster_embeddings,
    priority_scores=priority_scores,
    sectors=sectors,
    top_k_per_sector=2,  # Max 2 par secteur
    lambda_param=0.7
)
```

### üìä Nouveau Champ dans les Insights

```python
class EnrichedInsight(BaseModel):
    ...
    mmr_rank: Optional[int] = None  # Rang apr√®s MMR reranking
```

### üìç Fichiers Cr√©√©s
- `src/need_scanner/processing/mmr.py` : Module MMR

---

## 4. M√©moire Inter-Jour des Clusters

### üéØ Objectif
√âviter de remonter les **m√™mes id√©es tous les jours** en p√©nalisant les clusters similaires √† ceux d√©j√† vus.

### üìù Impl√©mentation

#### 4.1. Biblioth√®que d'Historique (JSONL)

Stockage des clusters pass√©s dans un fichier JSONL :

```json
{"id": "2025-01-25_3", "date": "2025-01-25", "title": "Freelance payment delays", "sector": "business_pme", "priority_score": 7.2, "embedding": [0.123, ...]}
{"id": "2025-01-25_7", "date": "2025-01-25", "title": "Dev tool for API testing", "sector": "dev_tools", "priority_score": 6.8, "embedding": [0.456, ...]}
```

**Param√®tres** :
```bash
NS_HISTORY_RETENTION_DAYS=30  # Conservation 30 jours
```

#### 4.2. P√©nalit√© de Similarit√©

**Formule** :
```
priority_score_adjusted = priority_score * (1 - Œ± * max_similarity)
```

- **Œ± = 0.3** (par d√©faut) : Facteur de p√©nalit√© (0-1)
- `max_similarity` : Similarit√© cosinus maximale avec l'historique

**Exemple** :
- Cluster nouveau : similarit√© = 0.0 ‚Üí **aucune p√©nalit√©**
- Cluster similaire (0.8) : p√©nalit√© = 0.3 * 0.8 = 0.24 ‚Üí **score r√©duit de 24%**
- Cluster quasi-identique (0.95) : p√©nalit√© = 0.3 * 0.95 = 0.285 ‚Üí **score r√©duit de 28.5%**

### üìä Nouveau Champ dans les Insights

```python
class EnrichedInsight(BaseModel):
    ...
    priority_score_adjusted: Optional[float] = None  # Score ajust√© avec p√©nalit√©
```

### üìç Fichiers Cr√©√©s
- `src/need_scanner/processing/history.py` : Gestion de l'historique
- `data/history/clusters.jsonl` : Fichier d'historique (cr√©√© automatiquement)

---

## 5. Scoring Plus Discriminant

### üéØ Objectif
Rendre les scores **pain, novelty, trend, WTP** plus **expressifs** et **discriminants**.

### üìù Am√©liorations du Prompt

**Avant** :
> Score de douleur de 1 √† 10 (10 = douleur forte, urgente, r√©currente)

**Apr√®s** :
```
Score de douleur de 1 √† 10. IMPORTANT : Utilise TOUTE l'√©chelle 1-10 de mani√®re discriminante :
- 1-3 = Inconv√©nient mineur, pas urgent, workarounds acceptables
- 4-6 = Probl√®me r√©el mais g√©rable, impact mod√©r√©
- 7-8 = Douleur forte, impact business significatif, besoin urgent
- 9-10 = Douleur critique/exceptionnelle, bloquant majeur (RARE - r√©serve pour cas vraiment exceptionnels)

Imagine que tu scores 100 probl√®mes diff√©rents : seuls quelques-uns m√©ritent 9-10. La plupart se situent entre 4-7.
Sois EXIGEANT et DISCRIMINANT dans ta notation.
```

### üìä Impact

**Avant** : Tous les clusters scorent entre 7-8 (peu discriminant)
**Apr√®s** : Distribution √©tal√©e entre 3-9 (hautement discriminant)

### üìç Fichiers Modifi√©s
- `src/need_scanner/analysis/summarize.py` : Am√©lioration du prompt

---

## 6. Configuration Multi-Secteur des Sources

### üéØ Objectif
Organiser les sources (Reddit, StackExchange) par **cat√©gories sectorielles** et √©chantillonner de mani√®re √©quilibr√©e.

### üìù Impl√©mentation

**Nouveau fichier de configuration** : `config/sources_config.yaml`

```yaml
reddit_sources:
  - name: freelance
    category: business_pme
    max_posts: 40

  - name: webdev
    category: dev_tools
    max_posts: 30

  - name: therapy
    category: health_wellbeing
    max_posts: 30

category_quotas:
  business_pme: 150
  dev_tools: 150
  health_wellbeing: 80
  ...
```

### üé® √âchantillonnage √âquilibr√©

```python
from src.need_scanner.fetchers.balanced_sampling import (
    load_sources_config,
    balance_posts_by_category
)

config = load_sources_config()
balanced_posts, counts = balance_posts_by_category(posts, config['category_quotas'])
```

**R√©sultat** :
- Garantit une **repr√©sentation √©quilibr√©e** de chaque secteur
- √âvite la surrepr√©sentation du dev/tech
- Permet de couvrir business, sant√©, √©ducation, retail, etc.

### üìç Fichiers Cr√©√©s
- `config/sources_config.yaml` : Configuration des sources
- `src/need_scanner/fetchers/balanced_sampling.py` : Module d'√©chantillonnage

---

## 7. Pipeline Enrichi Int√©gr√©

### üéØ Objectif
Int√©grer toutes les am√©liorations dans un pipeline unifi√© et optimis√©.

### üìù Workflow du Pipeline

```
1. Collecte ‚Üí Filtrage ‚Üí D√©duplication ‚Üí Embeddings ‚Üí Clustering
                           ‚Üì
2. Scoring heuristique initial (tous les clusters)
                           ‚Üì
3. Enrichissement TOP K avec mod√®le lourd (gpt-4o)
   + Enrichissement autres avec mod√®le l√©ger (gpt-4o-mini)
                           ‚Üì
4. Classification secteurs (avec gpt-4o-mini)
                           ‚Üì
5. Calcul priority_score (pain + traction + novelty + WTP)
                           ‚Üì
6. P√©nalit√© de similarit√© avec historique
   ‚Üí priority_score_adjusted
                           ‚Üì
7. MMR reranking par secteur (diversit√©)
   ‚Üí mmr_rank
                           ‚Üì
8. Export JSON/CSV + Mise √† jour historique
```

### üìä Utilisation

```python
from src.need_scanner.jobs.enriched_pipeline import run_enriched_pipeline

results = run_enriched_pipeline(
    cluster_data=cluster_data,
    embeddings=embeddings,
    labels=labels,
    output_dir=Path("data/results"),
    use_mmr=True,
    use_history_penalty=True
)

print(f"TOP 5 insights: {results['insights'][:5]}")
```

### üìç Fichiers Cr√©√©s
- `src/need_scanner/jobs/enriched_pipeline.py` : Pipeline int√©gr√©

---

## üéØ Utilisation Compl√®te

### 1. Configuration

```bash
# Copier le fichier .env.example
cp .env.example .env

# √âditer .env avec vos cl√©s API
nano .env
```

**Variables importantes** :
```bash
OPENAI_API_KEY=sk-...

# Mod√®les
NS_LIGHT_MODEL=gpt-4o-mini
NS_HEAVY_MODEL=gpt-4o
NS_TOP_K_ENRICHMENT=5

# Historique
NS_HISTORY_RETENTION_DAYS=30
NS_HISTORY_PENALTY_FACTOR=0.3

# MMR
NS_MMR_LAMBDA=0.7
NS_MMR_TOP_K=10
```

### 2. Installation des D√©pendances

```bash
pip install -r requirements.txt
```

**Nouvelle d√©pendance** : `pyyaml>=6.0.0`

### 3. Ex√©cution du Pipeline

```python
from pathlib import Path
from src.need_scanner.jobs.enriched_pipeline import run_enriched_pipeline
from src.need_scanner.processing.cluster import cluster, get_cluster_data
from src.need_scanner.processing.embed import embed_posts

# 1. Charger les posts
posts = load_posts_from_json("data/raw/posts_*.json")

# 2. Embeddings
embeddings, embed_cost = embed_posts(posts, api_key=config.openai_api_key)

# 3. Clustering
labels, kmeans = cluster(embeddings, n_clusters=10)
cluster_data = get_cluster_data(labels, posts, embeddings)

# 4. Pipeline enrichi
results = run_enriched_pipeline(
    cluster_data=cluster_data,
    embeddings=embeddings,
    labels=labels,
    output_dir=Path("data/results")
)

print(f"‚úÖ Pipeline termin√©. {results['num_top_insights']} insights g√©n√©r√©s.")
print(f"üí∞ Co√ªt total: ${results['total_cost']:.4f}")
```

---

## üìä Nouveaux Exports CSV

### Colonnes Ajout√©es

| Colonne | Description |
|---------|-------------|
| `sector` | Secteur du cluster (dev_tools, business_pme, etc.) |
| `priority_score_adjusted` | Score ajust√© avec p√©nalit√© historique |
| `mmr_rank` | Rang apr√®s MMR reranking |
| `source_category` | Cat√©gorie de la source (pour posts) |

---

## üß™ Tests

### Test du Pipeline Complet

```python
# Lancer le test
python test_enriched_pipeline.py
```

### Test Unitaire des Modules

```python
# Test MMR
from src.need_scanner.processing.mmr import mmr_rerank
# ... (voir tests/)

# Test History
from src.need_scanner.processing.history import ClusterHistory
# ... (voir tests/)

# Test Sector Classification
from src.need_scanner.analysis.sector import classify_cluster_sector
# ... (voir tests/)
```

---

## üìà M√©triques de Performance

### Avant les Am√©liorations

- ‚ö†Ô∏è Tous les clusters scor√©s de mani√®re similaire (7-8)
- ‚ö†Ô∏è Pas de diversit√© sectorielle
- ‚ö†Ô∏è R√©p√©titions quotidiennes des m√™mes id√©es
- ‚ö†Ô∏è Mod√®le unique pour tout

### Apr√®s les Am√©liorations

- ‚úÖ Scores √©tal√©s (3-9), hautement discriminants
- ‚úÖ Diversit√© multi-secteur garantie (MMR)
- ‚úÖ P√©nalit√© automatique des r√©p√©titions (historique)
- ‚úÖ Optimisation des co√ªts (mod√®les light/heavy)
- ‚úÖ TOP 5 ultra-qualitatif (gpt-4o)

---

## üöÄ Prochaines √âtapes (Optionnel)

### Notifications Slack Enrichies

Adapter la g√©n√©ration du message Slack pour afficher :
- TOP N global (MMR)
- OU mini TOP par secteur

```python
# TOP 1 par secteur
for sector in ['business_pme', 'dev_tools', 'health_wellbeing']:
    top_insight = next((i for i in insights if i.summary.sector == sector), None)
    if top_insight:
        print(f"üèÜ {sector}: {top_insight.summary.title}")
```

### Dashboard Interactif

Cr√©er un dashboard Streamlit avec :
- Filtre par secteur
- Graphique de distribution des scores
- Timeline historique
- Comparaison avant/apr√®s p√©nalit√©

---

## üìù Fichiers Cr√©√©s/Modifi√©s

### Fichiers Cr√©√©s

```
src/need_scanner/analysis/sector.py
src/need_scanner/processing/mmr.py
src/need_scanner/processing/history.py
src/need_scanner/fetchers/balanced_sampling.py
src/need_scanner/jobs/enriched_pipeline.py
config/sources_config.yaml
docs/ENGINE_IMPROVEMENTS.md
data/history/clusters.jsonl (auto-g√©n√©r√©)
```

### Fichiers Modifi√©s

```
src/need_scanner/config.py
src/need_scanner/schemas.py
src/need_scanner/analysis/summarize.py
.env.example
requirements.txt
```

---

## üí° Conseils d'Utilisation

### Contr√¥le des Co√ªts

1. **Limiter TOP_K_ENRICHMENT** : Plus ce nombre est petit, moins le pipeline co√ªte cher
2. **Ajuster NS_MMR_TOP_K** : S√©lectionner moins de clusters finaux r√©duit les co√ªts d'affichage
3. **D√©sactiver le mod√®le lourd** : Utiliser uniquement `gpt-4o-mini` pour tous les clusters (moins cher mais moins qualitatif)

### Optimiser la Diversit√©

1. **Augmenter Œª MMR** : Œª=0.8 privil√©gie la pertinence, Œª=0.5 privil√©gie la diversit√©
2. **Ajuster top_k_per_sector** : Limite le nombre de clusters par secteur dans le MMR

### G√©rer l'Historique

1. **Augmenter RETENTION_DAYS** : Garder plus d'historique (30-90 jours)
2. **Augmenter PENALTY_FACTOR** : P√©naliser plus fortement les r√©p√©titions (0.3-0.5)
3. **Nettoyer manuellement** : Supprimer `data/history/clusters.jsonl` pour repartir de z√©ro

---

## üÜò Support

Pour toute question ou probl√®me :
1. Consulter les logs (`loguru` activ√© par d√©faut)
2. V√©rifier la configuration (`.env` et `config/sources_config.yaml`)
3. Ouvrir une issue sur GitHub

---

**Made with ‚ù§Ô∏è using Claude Code**
