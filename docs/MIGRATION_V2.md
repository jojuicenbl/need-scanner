# üîÑ Guide de Migration v1.0 ‚Üí v2.0

Ce guide explique comment migrer d'un workflow Need Scanner v1.0 vers v2.0 avec toutes les nouvelles fonctionnalit√©s.

## üìã R√©sum√© des Changements

### Nouveaut√©s v2.0
- ‚úÖ Configuration multi-mod√®le (light/heavy)
- ‚úÖ Tags sectoriels automatiques
- ‚úÖ MMR reranking (diversit√©)
- ‚úÖ M√©moire inter-jour (historique)
- ‚úÖ Scoring plus discriminant
- ‚úÖ Sources multi-secteur √©quilibr√©es

### Compatibilit√©
- ‚úÖ **100% backward compatible** : Aucun code v1.0 ne casse
- ‚úÖ Toutes les commandes CLI existantes fonctionnent
- ‚úÖ Les anciens exports restent valides
- ‚úÖ Pas de changement obligatoire

---

## üöÄ Migration √âtape par √âtape

### √âtape 1 : Installation des Nouvelles D√©pendances

```bash
# Activer environnement virtuel
source env/bin/activate  # ou env\Scripts\activate sur Windows

# Installer PyYAML (seule nouvelle d√©pendance)
pip install pyyaml>=6.0.0

# OU r√©installer tout
pip install -r requirements.txt
```

**V√©rification** :
```bash
python test_improvements.py
# Doit afficher : ‚úÖ ALL TESTS PASSED
```

---

### √âtape 2 : Mise √† Jour Configuration

#### 2.1. Fichier `.env`

Ajouter ces variables √† votre `.env` existant :

```bash
# === NOUVELLES VARIABLES v2.0 ===

# Mod√®les OpenAI
NS_LIGHT_MODEL=gpt-4o-mini          # Mod√®le l√©ger (classification, tags)
NS_HEAVY_MODEL=gpt-4o               # Mod√®le puissant (TOP K clusters)
NS_TOP_K_ENRICHMENT=5               # Nombre de TOP clusters avec gpt-4o

# Historique & D√©duplication
NS_HISTORY_RETENTION_DAYS=30        # Jours de r√©tention historique
NS_HISTORY_PENALTY_FACTOR=0.3       # Force de p√©nalit√© (0-1)

# MMR Reranking
NS_MMR_LAMBDA=0.7                   # Balance relevance/diversit√© (0-1)
NS_MMR_TOP_K=10                     # Nombre final de clusters s√©lectionn√©s
```

**Ou copier depuis le template** :
```bash
# Sauvegarder votre .env actuel
cp .env .env.backup

# Copier le nouveau template
cp .env.example .env

# Restaurer votre OPENAI_API_KEY
# (copier manuellement depuis .env.backup)
```

#### 2.2. Configuration Sources (Optionnel)

Le fichier `config/sources_config.yaml` est **pr√©-configur√©** et pr√™t √† l'emploi.

**Si vous voulez le personnaliser** :
```bash
nano config/sources_config.yaml
```

Sinon, rien √† faire !

---

### √âtape 3 : Choix du Mode d'Utilisation

Vous avez **3 options** pour utiliser les am√©liorations v2.0 :

#### Option A : Mode Hybride (Recommand√©)

Garder votre workflow actuel + utiliser le pipeline v2.0 pour les analyses importantes.

**Workflow v1.0 existant** (toujours fonctionnel) :
```bash
# Collecte
python -m need_scanner collect-reddit-multi --limit-per-sub 30

# Analyse standard
python -m need_scanner run --input "data/raw/posts_*.json" --clusters 10
```

**Pipeline v2.0** (analyses premium) :
```python
# Script Python personnalis√© (voir √âtape 4)
python scripts/run_v2_pipeline.py
```

#### Option B : Migration Compl√®te vers v2.0

Remplacer compl√®tement votre workflow par le pipeline v2.0.

**Avantages** :
- Toutes les fonctionnalit√©s v2.0
- Meilleure qualit√© sur TOP K
- Diversit√© sectorielle garantie

**Inconv√©nients** :
- N√©cessite code Python (pas de CLI simple)
- Co√ªt l√©g√®rement plus √©lev√© (gpt-4o sur TOP K)

#### Option C : Rester en v1.0

Continuer avec le workflow actuel sans changement.

**Quand choisir cette option** :
- Votre workflow actuel vous convient
- Budget limit√© (v1.0 = moins cher)
- Pas besoin de diversit√© sectorielle

**Note** : Vous pouvez migrer plus tard sans probl√®me.

---

### √âtape 4 : Cr√©er un Script v2.0 (Options A ou B)

Cr√©er un fichier `scripts/run_v2_pipeline.py` :

```python
"""
Script personnalis√© pour ex√©cuter le pipeline Need Scanner v2.0.
Adapt√© √† votre workflow existant.
"""

import glob
import json
import numpy as np
from pathlib import Path

from src.need_scanner.config import get_config
from src.need_scanner.schemas import Post
from src.need_scanner.processing.embed import embed_posts
from src.need_scanner.processing.cluster import cluster, get_cluster_data
from src.need_scanner.jobs.enriched_pipeline import run_enriched_pipeline


def main():
    """Pipeline v2.0 avec toutes les am√©liorations."""

    # Configuration
    config = get_config()
    output_dir = Path("data/results_v2")

    print("=" * 60)
    print("üöÄ Need Scanner v2.0 - Enhanced Pipeline")
    print("=" * 60)

    # 1. Charger les posts collect√©s
    print("\n[1/5] Loading posts...")
    posts_files = glob.glob("data/raw/posts_*.json")

    if not posts_files:
        print("‚ùå No posts found in data/raw/")
        print("   Run: python -m need_scanner collect-reddit-multi --limit-per-sub 30")
        return

    all_posts = []
    for file_path in posts_files:
        with open(file_path, 'r', encoding='utf-8') as f:
            posts_data = json.load(f)
            all_posts.extend([Post(**p) for p in posts_data])

    print(f"‚úì Loaded {len(all_posts)} posts from {len(posts_files)} files")

    # 2. Filtrage optionnel (comme en v1.0)
    # Vous pouvez ajouter des filtres ici si besoin

    # 3. Embeddings
    print("\n[2/5] Generating embeddings...")
    embeddings, embed_cost = embed_posts(
        posts=all_posts,
        api_key=config.openai_api_key,
        model=config.ns_embed_model
    )
    print(f"‚úì Generated embeddings. Cost: ${embed_cost:.4f}")

    # 4. Clustering
    print("\n[3/5] Clustering...")
    n_clusters = min(config.ns_num_clusters, len(all_posts))
    labels, kmeans = cluster(embeddings, n_clusters=n_clusters)

    metadata = [p.dict() for p in all_posts]
    cluster_data = get_cluster_data(labels, metadata, embeddings)

    print(f"‚úì Created {len(cluster_data)} clusters")

    # 5. Pipeline enrichi v2.0
    print("\n[4/5] Running enriched pipeline (v2.0)...")
    print("   - Multi-model enrichment (light/heavy)")
    print("   - Sector classification")
    print("   - History-based deduplication")
    print("   - MMR reranking for diversity")

    results = run_enriched_pipeline(
        cluster_data=cluster_data,
        embeddings=embeddings,
        labels=labels,
        output_dir=output_dir,
        use_mmr=True,
        use_history_penalty=True
    )

    # 6. R√©sum√©
    print("\n[5/5] Summary")
    print("=" * 60)
    print(f"‚úÖ Pipeline complete!")
    print(f"   Total clusters: {results['num_clusters']}")
    print(f"   TOP insights: {results['num_top_insights']}")
    print(f"   Total cost: ${results['total_cost']:.4f}")
    print(f"   Results saved to: {output_dir}")

    # Afficher TOP 5
    print("\nüèÜ TOP 5 INSIGHTS:")
    for insight in results['insights'][:5]:
        sector_emoji = {
            'dev_tools': 'üíª',
            'business_pme': 'üíº',
            'health_wellbeing': 'üè•',
            'education_learning': 'üìö',
            'ecommerce_retail': 'üõí',
            'marketing_sales': 'üìä',
        }.get(insight.summary.sector, 'üìå')

        print(f"\n  #{insight.rank} {sector_emoji} [{insight.summary.sector}]")
        print(f"     {insight.summary.title}")
        print(f"     Priority: {insight.priority_score:.2f} ‚Üí {insight.priority_score_adjusted:.2f}")
        print(f"     MMR rank: {insight.mmr_rank}")

    print("\n" + "=" * 60)
    print("üìñ See docs/ENGINE_IMPROVEMENTS.md for detailed documentation")
    print("=" * 60)


if __name__ == "__main__":
    main()
```

**Rendre le script ex√©cutable** :
```bash
chmod +x scripts/run_v2_pipeline.py
```

**Ex√©cuter** :
```bash
python scripts/run_v2_pipeline.py
```

---

### √âtape 5 : Comparer v1.0 vs v2.0

Pour √©valuer les am√©liorations, lancez les deux pipelines en parall√®le :

```bash
# Pipeline v1.0
python -m need_scanner run --input "data/raw/posts_*.json" --output-dir data/results_v1

# Pipeline v2.0
python scripts/run_v2_pipeline.py  # Output: data/results_v2
```

**Comparer** :
1. **Diversit√©** : v2.0 devrait montrer plus de secteurs diff√©rents
2. **Qualit√© TOP 5** : v2.0 utilise gpt-4o pour meilleure analyse
3. **R√©p√©titions** : v2.0 p√©nalise les clusters similaires √† l'historique
4. **Scores** : v2.0 a des scores plus √©tal√©s (3-9 vs 7-8)

---

## üìä Ajustements Recommand√©s

### Optimiser les Co√ªts

Si le co√ªt v2.0 est trop √©lev√© :

```bash
# .env
NS_TOP_K_ENRICHMENT=3  # R√©duire √† 3 au lieu de 5
NS_HEAVY_MODEL=gpt-4o-mini  # Utiliser uniquement le mod√®le l√©ger
```

### Augmenter la Diversit√©

Pour favoriser encore plus la diversit√© :

```bash
# .env
NS_MMR_LAMBDA=0.5  # Plus de diversit√© (50/50 relevance/diversity)
```

### Ajuster la M√©moire Historique

Pour p√©naliser plus fortement les r√©p√©titions :

```bash
# .env
NS_HISTORY_PENALTY_FACTOR=0.5  # P√©nalit√© plus forte
NS_HISTORY_RETENTION_DAYS=60   # Garder plus longtemps
```

---

## üîß Int√©gration dans GitHub Actions

Si vous utilisez GitHub Actions pour l'ex√©cution quotidienne :

### Mettre √† jour `.github/workflows/need_scanner_daily.yml`

```yaml
name: Need Scanner Daily (v2.0)

on:
  schedule:
    - cron: '0 8 * * *'  # 8h chaque jour
  workflow_dispatch:

jobs:
  run-scanner:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt

      - name: Run v2.0 pipeline
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: |
          python scripts/run_v2_pipeline.py

      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: results-v2
          path: data/results_v2/
```

---

## üß™ Tester la Migration

### Checklist de V√©rification

- [ ] Tests passent : `python test_improvements.py` ‚úÖ
- [ ] Configuration `.env` mise √† jour
- [ ] Script v2.0 cr√©√© et test√©
- [ ] R√©sultats v2.0 contiennent nouveaux champs (`sector`, `mmr_rank`, etc.)
- [ ] Historique cr√©√© : `data/history/clusters.jsonl` existe
- [ ] Co√ªts sous contr√¥le (v√©rifier les logs)

### Test Complet

```bash
# 1. Collecter donn√©es fra√Æches
python -m need_scanner collect-reddit-multi --limit-per-sub 20

# 2. Pipeline v1.0 (r√©f√©rence)
python -m need_scanner run --input "data/raw/posts_*.json" --output-dir data/results_v1

# 3. Pipeline v2.0 (nouveau)
python scripts/run_v2_pipeline.py

# 4. Comparer les r√©sultats
ls -lh data/results_v1/
ls -lh data/results_v2/

# 5. Inspecter un insight v2.0
cat data/results_v2/enriched_results.json | jq '.[0]'
```

---

## ‚ùì FAQ Migration

**Q: Dois-je supprimer mes anciens r√©sultats ?**
R: Non, v1.0 et v2.0 peuvent coexister. Gardez `data/results/` pour v1.0 et utilisez `data/results_v2/` pour v2.0.

**Q: L'historique ralentit-il le pipeline ?**
R: Non, impact n√©gligeable (<1s). Peut m√™me acc√©l√©rer en r√©duisant les clusters √† analyser.

**Q: Puis-je d√©sactiver certaines fonctionnalit√©s v2.0 ?**
R: Oui, via param√®tres `use_mmr=False` et `use_history_penalty=False` dans `run_enriched_pipeline()`.

**Q: Que se passe-t-il si je ne configure pas les nouvelles variables .env ?**
R: Les valeurs par d√©faut seront utilis√©es (d√©finies dans `config.py`). Le pipeline fonctionnera quand m√™me.

**Q: Comment r√©initialiser l'historique ?**
R: Supprimer `data/history/clusters.jsonl` ou lancer `history.cleanup_old_entries(retention_days=0)`.

**Q: Le pipeline v2.0 est-il plus lent ?**
R: L√©g√®rement (~10-20% plus lent) √† cause des √©tapes suppl√©mentaires (sector classification, MMR, history). Mais la qualit√© est bien meilleure.

---

## üÜò D√©pannage

### Probl√®me : Tests √©chouent

```bash
# V√©rifier Python version
python --version  # Doit √™tre 3.11+

# R√©installer d√©pendances
pip install --upgrade -r requirements.txt

# Relancer tests
python test_improvements.py
```

### Probl√®me : Erreur "No module named 'yaml'"

```bash
pip install pyyaml
```

### Probl√®me : Historique corrompu

```bash
rm data/history/clusters.jsonl
# Relancer le pipeline
```

### Probl√®me : Co√ªts trop √©lev√©s

```bash
# R√©duire TOP K enrichment
echo "NS_TOP_K_ENRICHMENT=2" >> .env

# OU utiliser uniquement mod√®le l√©ger
echo "NS_HEAVY_MODEL=gpt-4o-mini" >> .env
```

---

## üìö Ressources

- **Documentation compl√®te** : [docs/ENGINE_IMPROVEMENTS.md](ENGINE_IMPROVEMENTS.md)
- **Quick Start v2.0** : [QUICK_START_V2.md](../QUICK_START_V2.md)
- **Changelog** : [CHANGELOG.md](../CHANGELOG.md)
- **Tests** : `test_improvements.py`

---

## üéâ F√©licitations !

Vous avez migr√© vers Need Scanner v2.0 avec succ√®s !

**Profitez des nouvelles fonctionnalit√©s** :
- üéØ Insights multi-secteur diversifi√©s
- üíé TOP K ultra-qualitatif (gpt-4o)
- üîÑ D√©duplication automatique inter-jour
- üìä Scoring plus expressif et discriminant

**Happy market discovery! üöÄ**
